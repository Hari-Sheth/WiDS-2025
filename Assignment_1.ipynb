{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ASSIGNMENT 1: NEURAL NETWORKS"
      ],
      "metadata": {
        "id": "Ph86zXO3SfjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write the entire code of the given Handwritten image recognition on your own and run it and obtain your loss and accuracy\n",
        "\n",
        "2. Tuning your hyper parameters: take 3 values of lr and batch size each and check which works best\n",
        "\n",
        "3. Write a digit on paper and pass it on to the model and view the outputs. see wheteher it works or not, if not think of of a reason why?"
      ],
      "metadata": {
        "id": "zJ_-xLbDSrbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np                                                              #importing important libraries.\n",
        "import matplotlib.pyplot as plt                                                 #importing important libraries.\n",
        "import pandas as pd                                                             #importing important libraries.\n",
        "import keras                                                                    #importing important libraries.\n",
        "from keras.datasets import mnist                                                #importing important libraries."
      ],
      "metadata": {
        "id": "sjxxnvY3WhQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()                         #loading the training dataset.\n",
        "print(x_train.shape)\n",
        "x_train[0][0][5]"
      ],
      "metadata": {
        "id": "trDOvNIYWm1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1fff495-6bc0-4860-ec72-f2aa8cf8657c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "(60000, 28, 28)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.uint8(0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#Creating a neural network of 3 layers just as in sample code\n",
        "\n",
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super(NN, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, 256)\n",
        "    self.fc2 = nn.Linear(256, 128)\n",
        "    self.fc3 = nn.Linear(128, output_size)\n",
        "    self.bn1 = nn.BatchNorm1d(256)\n",
        "    self.bn2 = nn.BatchNorm1d(128)\n",
        "    self.dropout = nn.Dropout(0.19)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = F.relu(self.bn1(self.fc1(x)))\n",
        "    x = self.dropout(x)\n",
        "    x = F.relu(self.bn2(self.fc2(x)))\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "DXtMOWIAWm93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class dataset(Dataset):\n",
        "  def __init__(self, images, labels):\n",
        "    self.images = images\n",
        "    self.labels = labels\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "  def __getitem__(self, index):\n",
        "    image = self.images[index]\n",
        "    label = self.labels[index]\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "btOsCUugWnB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sizes = [32, 64, 128]\n",
        "num_epochs = 40\n",
        "learning_rates = [0.001, 0.00125, 0.0015]\n",
        "input_size = 28*28\n",
        "output_size = 10\n",
        "Loss = [[] for _ in range(len(batch_sizes))]"
      ],
      "metadata": {
        "id": "1WCrlT1CWnE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs = batch_sizes[2]\n",
        "lr = learning_rates[0]\n",
        "train_data = DataLoader(dataset(x_train, y_train),\n",
        "               batch_size=bs,\n",
        "               shuffle=True)\n",
        "\n",
        "test_data = DataLoader(dataset(x_test, y_test),\n",
        "               batch_size=bs,\n",
        "               shuffle=True)"
      ],
      "metadata": {
        "id": "051Kf7iTwWya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model  = NN(input_size = input_size, output_size = output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "aCnzgnb7WhTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#==================================================TRAINING==================================================#\n",
        "# ._____________. .______.          .______       ._____________.*._______     ___. ._____________. ._______     ___.    _________\n",
        "#*|_____   _____|*|   _   \\******* /  __.  \\******|_____   _____| |       \\****|  |*|_____   _____|*|       \\****|  |***/   ______\\******\n",
        "#******|   |**** *|  |_|   )******/  /___\\  \\**********|   |******|   |\\   \\***|  |* ****|   |******|   |\\   \\***|  |**/   /*************\n",
        "#******|   |**** *|       /******/   .___.   \\*********|   |******|   |*\\   \\**|  |* ****|   |******|   |*\\   \\**|  |*|   /*** ______****\n",
        "#******|   |**** *|   |\\  \\*****/   /*****\\   \\********|   |******|   |**\\   \\*|  |* ****|   |******|   |**\\   \\*|  |*|   \\***|__    )***\n",
        "#******|   |**** *|   | \\  \\***/   /*******\\   \\**.____|   |____.*|   |***\\   \\|  |*.____|   |____.*|   |***\\   \\|  |**\\   \\____/   /****\n",
        "#******|___|**** *|___|  \\__\\*/___/*********\\___\\ |_____________|*|___|****\\______|*|_____________|*|___|****\\______|***\\__________/*****\n",
        "i = 0\n",
        "#iteration = [i for i in range (41)]\n",
        "for epoch in range(num_epochs):\n",
        "  i += 1\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  for images, labels in train_data:\n",
        "    images = images.float()\n",
        "    labels = labels.long()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(images)\n",
        "    loss = criterion(output, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "    #if i%10 == 0: print(i)\n",
        "  epoch_loss = running_loss/len(train_data)\n",
        "  #if (bs == 32):\n",
        "  #  Loss[0].append(epoch_loss)\n",
        "  #elif (bs == 64):\n",
        "  #  Loss[1].append(epoch_loss)\n",
        "  #elif (bs == 128):\n",
        "  #  Loss[2].append(epoch_loss)\n",
        "  print(i, \" Epoch: \", (epoch+1)/(num_epochs), \" Loss: \", epoch_loss)\n",
        "\n"
      ],
      "metadata": {
        "id": "Mk1yFMIoWhWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f81bec-70b0-4d5f-8464-73f434a0b8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1  Epoch:  0.025  Loss:  0.28316190647386286\n",
            "2  Epoch:  0.05  Loss:  0.11653830549483106\n",
            "3  Epoch:  0.075  Loss:  0.08910284628436319\n",
            "4  Epoch:  0.1  Loss:  0.07288389243701818\n",
            "5  Epoch:  0.125  Loss:  0.062273171879271706\n",
            "6  Epoch:  0.15  Loss:  0.05448811031036031\n",
            "7  Epoch:  0.175  Loss:  0.048433415165770724\n",
            "8  Epoch:  0.2  Loss:  0.04269515264775358\n",
            "9  Epoch:  0.225  Loss:  0.038827416441862043\n",
            "10  Epoch:  0.25  Loss:  0.03556171684875401\n",
            "11  Epoch:  0.275  Loss:  0.033037518796973676\n",
            "12  Epoch:  0.3  Loss:  0.03065735620629193\n",
            "13  Epoch:  0.325  Loss:  0.030337800215214872\n",
            "14  Epoch:  0.35  Loss:  0.027984457576015927\n",
            "15  Epoch:  0.375  Loss:  0.027389812332365527\n",
            "16  Epoch:  0.4  Loss:  0.026330475729933855\n",
            "17  Epoch:  0.425  Loss:  0.024157495378751927\n",
            "18  Epoch:  0.45  Loss:  0.020897953243090163\n",
            "19  Epoch:  0.475  Loss:  0.021934542833501772\n",
            "20  Epoch:  0.5  Loss:  0.020034678590628924\n",
            "21  Epoch:  0.525  Loss:  0.019481535860102005\n",
            "22  Epoch:  0.55  Loss:  0.01903421462410247\n",
            "23  Epoch:  0.575  Loss:  0.0167936191260904\n",
            "24  Epoch:  0.6  Loss:  0.01928029138334731\n",
            "25  Epoch:  0.625  Loss:  0.01720269142624253\n",
            "26  Epoch:  0.65  Loss:  0.017267021586806246\n",
            "27  Epoch:  0.675  Loss:  0.016511717812467946\n",
            "28  Epoch:  0.7  Loss:  0.015151616134708112\n",
            "29  Epoch:  0.725  Loss:  0.015213416287810035\n",
            "30  Epoch:  0.75  Loss:  0.015015550763165054\n",
            "31  Epoch:  0.775  Loss:  0.014504021456798237\n",
            "32  Epoch:  0.8  Loss:  0.014643097826245446\n",
            "33  Epoch:  0.825  Loss:  0.014415383386493438\n",
            "34  Epoch:  0.85  Loss:  0.012777342979643823\n",
            "35  Epoch:  0.875  Loss:  0.012464638688164189\n",
            "36  Epoch:  0.9  Loss:  0.013363053552032675\n",
            "37  Epoch:  0.925  Loss:  0.012710718369055072\n",
            "38  Epoch:  0.95  Loss:  0.013042288635589821\n",
            "39  Epoch:  0.975  Loss:  0.013198893593955856\n",
            "40  Epoch:  1.0  Loss:  0.009933376696078912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XAf-wyuB7lAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#==================================================TESTING==================================================#\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_data:\n",
        "  images = images.float()\n",
        "  labels = labels.long()\n",
        "  output = model(images)\n",
        "  loss = criterion(output, labels)\n",
        "  correct += (output.argmax(1) == labels).sum().item()\n",
        "  total += labels.size(0)\n",
        "print(100*correct/total)"
      ],
      "metadata": {
        "id": "VtdWwvJVWhZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "effe6ffa-bbf3-4a4d-ed39-9ad39ada827e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98.44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inferences:\n",
        "<br>\n",
        "\n",
        "Table 1: Loss dependency on batch size and learning rate.\n",
        "|Learning_rate\\Batch_size|    32    |    64    |    128   |\n",
        "|:-----------------------|:--------:|:--------:|:--------:|\n",
        "|0.001                   |  0.0258  |  0.0179  |  0.0118  |\n",
        "|0.00125                 |  0.0250  |  0.0166  |  0.0130  |\n",
        "|0.0015                  |  0.0277  |  0.0165  |  0.0134  |\n",
        "<br>\n",
        "\n",
        "Table 2: Accuracy dependency on batch size and learning rate.\n",
        "<br>\n",
        "\n",
        "| Learning_rate\\Batch_size |   32    |    64   |   128   |\n",
        "|:-------------------------|:-------:|:-------:|:-------:|\n",
        "|0.001                     |  98.46  |  98.37  |  98.44  |\n",
        "|0.00125                   |  98.54  |  98.48  |  98.56  |\n",
        "|0.0015                    |  98.37  |  98.56  |  98.46  |\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "gU70Q62DrZ61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "images = [torch.zeros(1,28,28) for _ in range(10)]\n",
        "images[0] = Image.open(\"/drive/MyDrive/Colab Notebooks/WiDS Assignment 1/Digits/0.jpg\")\n",
        "images[1] = Image.open(\"/drive/MyDrive/Colab Notebooks/WiDS Assignment 1/Digits/1.jpg\")\n",
        "images[2] = Image.open(\"/drive/MyDrive/Colab Notebooks/WiDS Assignment 1/Digits/2.jpg\")\n",
        "images[3] = Image.open(\"/drive/MyDrive/Colab Notebooks/WiDS Assignment 1/Digits/3.jpg\")\n",
        "images[4] = Image.open(\"/drive/MyDrive/Colab Notebooks/WiDS Assignment 1/Digits/4.jpg\")\n",
        "images[5] = Image.open(\"/drive/MyDrive/Colab Notebooks/WiDS Assignment 1/Digits/5.jpg\")\n",
        "images[6] = Image.open(\"/drive/MyDrive/Colab Notebooks/WiDS Assignment 1/Digits/6.jpg\")\n",
        "images[7] = Image.open(\"/drive/MyDrive/Colab Notebooks/WiDS Assignment 1/Digits/7.jpg\")\n",
        "images[8] = Image.open(\"/drive/MyDrive/Colab Notebooks/WiDS Assignment 1/Digits/8.jpg\")\n",
        "images[9] = Image.open(\"/drive/MyDrive/Colab Notebooks/WiDS Assignment 1/Digits/9.jpg\")\n",
        "\n",
        "i = 0\n",
        "image = Image.open(\"/drive/MyDrive/Colab Notebooks/WiDS Assignment 1/mnist8.png\")\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(1),\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Lambda(lambda x: 1-x),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "image = transform(image)\n",
        "#image = image.view(1, 28 , 28)\n",
        "print(\"Image shape:\", image.shape)\n",
        "#image = image.float()\n",
        "#image = 1 - image\n",
        "#image = image.sqrt()\n",
        "#min_val = image.min()\n",
        "#max_val = image.max()\n",
        "image = (image - image.min())/(image.max()-image.min()) * 255\n",
        "#image[image < 0.4] = 0.0\n",
        "print(image.max(), image.min())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM2pEvMx9qrs",
        "outputId": "5be79729-cde6-4aa5-81b5-446afde1396d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28])\n",
            "tensor(255.) tensor(0.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "plt.title(\"Check and Verify transform\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "HxJ2ENhg_C2k",
        "outputId": "15f6c190-911d-4eca-8b28-952f793370e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHkpJREFUeJzt3XlwVfX9//FXErJAQlgkGCCRJaxhUXBDdgEJYhAYREGE4MKguLS2ShfHQWsVKx1EARGmgsiwOEpBRyuLQxEV0I60LCJlMezIIhKUIIHk/fuDL+8SApLPle0nz8dMZszJeZ3zOede7uueu3yMMjMTAACSoi/0AAAAFw9KAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SuECiYqK0kMPPXRe97lp0yZFRUXpr3/963ndb6innnpKUVFRF3oYxbz++uuKiorSpk2bii0fOXKk6tSpo5iYGF111VUXZGwXyvr169WlSxdVqFBBUVFRmjNnzoUeEs4CSuEs27hxo4YMGaI6deooISFBycnJat26tV566SUdOnToQg/vF+HIkSOqUqWK2rRpc9p1zEzp6elq0aLFORvH/PnzNWzYMLVu3VqTJ0/Wc88997O2l5+fr6eeekqLFi06OwM8x3JycrRq1So9++yzmjp1qq655poLPSScBWUu9AB+Sd5//3316dNH8fHxGjhwoJo0aaKCggJ98sknevzxx/Xll19q4sSJF3qY/9+LjY1Vnz59NGHCBG3evFk1a9Yssc7ixYu1bds2Pfroo2dlnwMGDFDfvn0VHx/vyxYuXKjo6Gi99tpriouL+9n7yM/P19NPPy1J6tChw8/e3rl06NAhLV26VE888cR5v+LFucWVwlmSm5urvn37qmbNmlqzZo1eeuklDR48WA8++KBmzJihNWvWqHHjxhd6mL8Y/fv3l5lpxowZp/z79OnTFR0drb59+/6s/Rw8eFCSFBMTo4SEhGIva+3evVtly5Y9K4Xwc8Z2IezZs0eSVLFixbO2zQt5PDiB4ay4//77TZJ9+umnpVpfkj344IM2e/Zsa9y4scXFxVlmZqZ98MEHJdbdtm2b3X333Va1alVf77XXXiux3qFDh2z48OFWr149i4+Pt9TUVOvVq5dt2LDBzMxyc3NNko0cOdIzRUVFNnjwYIuNjbVZs2b95JhHjhxpN9xwg1WuXNkSEhKsRYsW9tZbb/2sY/v444/tmmuusfj4eKtTp469+uqrNnz4cDvTXbOoqMhq1aplTZs2LfG3goICq1y5snXq1MmXffXVV9a7d2+rVKmSxcfH29VXX23vvPNOsdzkyZNNki1atMgeeOABS0lJsYoVKxb7W25urh/jyT9jxoyxcuXK2SOPPFJiTFu3brXo6Gh77rnnTnk8x2+bk3+GDx9uZmY5OTmWmJhoGzZssJtvvtmSkpKsR48eZma2ePFiu+222yw9Pd3i4uIsLS3Nfv3rX1t+fn6xfRzfxrZt26xHjx6WmJhoVapUsd/+9rd29OjRYuvOmDHDWrRoYUlJSVa+fHlr0qSJjR492szMb58Tf2rWrOnZ5cuXW9euXa18+fKWmJhoHTt2tKVLl5b6XLdv394aN25sK1assHbt2lnZsmUtIyPD72uLFi2y6667zhISEqx+/fq2YMGCU55TRIZSOEtq1KhhderUKfX6kuzKK6+0atWq2TPPPGOjR4+2OnXqWLly5Wzv3r2+3jfffGNpaWmWnp5uf/rTn2z8+PF26623miR78cUXfb2jR49ap06dTJL17dvXxo4dayNGjLCOHTvanDlzzKxkKRw9etQGDhxo8fHx9t57751xzGlpaTZ06FAbO3asjRo1yq677jqTVCJb2mNbuXKllS1b1q644gobMWKEPfPMM3b55Zdbs2bNzlgKZmZ//OMfTZKtXr262PJ3333XJNmkSZPMzGz16tVWoUIFy8zMtL/85S82duxYa9eunUVFRdnf//53zx1/oMrMzLT27dvbmDFj7Pnnny/2t+OlMHXqVGvbtq3Fx8fb1KlTberUqbZx40br37+/XX755SUeZF944QWLioqyzZs3n/JYfvjhBxs/frxJsl69evk2V6xYYWbHHtDj4+MtIyPDcnJy7NVXX7U33njDzMwefvhh69atmz333HM2YcIEu/feey0mJsZuu+22YvvIycmxhIQEa9y4sd1zzz02fvx46927t0myV155xdebP3++SbJOnTrZuHHjbNy4cfbQQw9Znz59zMxsxYoV9uKLL5ok69evn02dOtVmz57t5zoxMdFv++eff95q165t8fHxtmzZslKd6/bt21v16tUtPT3dHn/8cRszZoxlZmZaTEyMzZw501JTU+2pp56y0aNHW40aNaxChQp24MCBM9xbUFqUwlmQl5dnkvyZW2lIsri4OH8Wb3bsH9vxZ5zH3XvvvVatWrViD6ZmZn379rUKFSr4s8FJkyaZJBs1alSJfRUVFZlZ8VI4cuSI3XHHHVa2bFmbN29eqcZ88jPPgoICa9KkiXXs2DGiY+vZs6clJCQUe6Bcs2aNxcTElKoUvvzyS5Nkf/jDH4ot79u3ryUkJFheXp6ZmXXq1MmaNm1qP/74o69TVFRkrVq1snr16vmy4w9Ubdq0KfGgfnIpmP3vmfeJ5s2bZ5JKXBU1a9bM2rdv/5PHs2fPnmJXByfKyckxSfb73/++xN9Ovl3MzEaMGFGihI5v409/+lOxdZs3b25XX321//6rX/3KkpOTS5yDE53qqtPs2G0aFxdnGzdu9GU7duyw8uXLW7t27XzZT53r9u3bmySbPn26L1u7dq1Jsujo6GLlcvx8T548+bRjRRjeUzgLDhw4IEkqX758UK5z587KyMjw35s1a6bk5GR9/fXXko59gmbWrFnq3r27zEx79+71n6ysLOXl5Wn58uWSpFmzZqlKlSp6+OGHS+zn5I93FhQUqE+fPnrvvff0j3/8Q126dCnVeMuWLev//d133ykvL09t27b1MYQcW2FhoebNm6eePXvqiiuu8PUaNWqkrKysUo0nMzNTzZs318yZM33ZwYMH9e677yo7O1vJycnat2+fFi5cqNtvv13ff/+9n79vv/1WWVlZWr9+vbZv315su4MHD1ZMTEypxnCq465evbqmTZvmy1avXq2VK1fqrrvuimibJ3rggQdKLDvxdjl48KD27t2rVq1aycz073//u8T6999/f7Hf27Zt67eLdOx9goMHD2rBggVBYyssLNT8+fPVs2dP1alTx5dXq1ZNd955pz755BP/t3Lc6c51UlJSsfeDGjRooIoVK6pRo0a6/vrrffnx/z5x/Ph5KIWzIDk5WZL0/fffB+VOfDA8rlKlSvruu+8kHXszb//+/Zo4caJSUlKK/dx9992Sjr3ZKR37KGyDBg1UpsyZP1A2YsQIzZkzR2+//XbQp1zee+89tWzZUgkJCapcubJSUlI0fvx45eXlRXRshw4dUr169Uqs16BBg1KPqX///srNzdWSJUskSXPmzFF+fr769+8vSdqwYYPMTE8++WSJczh8+HBJ/zuHx9WuXbvU+z9ZdHS0+vfv7+OQpGnTpikhIUF9+vSJeLuSVKZMGaWlpZVYvmXLFg0aNEiVK1dWUlKSUlJS1L59e0kqcdskJCQoJSWl2LITbxdJGjp0qOrXr6+bb75ZaWlpuueeezR37twzjm/Pnj3Kz88/5e3XqFEjFRUVaevWrcWWn+5cp6WllXgyU6FCBaWnp5dYJqnY+PHz8JHUsyA5OVnVq1fX6tWrg3KnezZq//d/SC0qKpIk3XXXXcrJyTnlus2aNQvapyRlZWVp7ty5euGFF9ShQwclJCScMfPxxx/r1ltvVbt27fTKK6+oWrVqio2N1eTJkzV9+vQS65/p2M6Wfv36adiwYZo+fbpatWql6dOnq1KlSurWrZuk/53Dxx577LRXIHXr1i32+4nPvCMxcOBAjRw5UnPmzFG/fv00ffp0ZWdn+wNYpOLj4xUdXfx5XGFhoW666Sbt27dPv/vd79SwYUMlJiZq+/btGjRokB//caW5Aqpatar+85//aN68efrggw/0wQcfaPLkyRo4cKCmTJnys47hZKc716cb5/m6X13KKIWzJDs7WxMnTtTSpUt1ww03nJVtpqSkqHz58iosLFTnzp1/ct2MjAx99tlnOnLkiGJjY39y3ZYtW+r+++9Xdna2+vTpo9mzZ5/xCmPWrFlKSEjQvHnzin1Wf/LkyaU/oBOkpKSobNmyWr9+fYm//fe//y31dqpXr64bb7xRb731lp588kktWLBAgwYN8o+JHn8ZIzY29ozn8Gxp0qSJmjdvrmnTpiktLU1btmzRmDFjzpiL5Fvcq1at0rp16zRlyhQNHDjQl4e+9HOyuLg4de/eXd27d1dRUZGGDh2qCRMm6MknnyxRoselpKSoXLlyp7z91q5dq+jo6BLP9HHx4eWjs2TYsGFKTEzUfffdp127dpX4+8aNG/XSSy8FbTMmJka9e/fWrFmzTnkVcvyz4pLUu3dv7d27V2PHji2x3qmeRXXu3FkzZ87U3LlzNWDAgBLPKE81lqioKBUWFvqyTZs2RTy1QUxMjLKysjRnzhxt2bLFl3/11VeaN29e0Lb69++v3bt3a8iQITpy5Ii/dCQde9bboUMHTZgwQTt37iyRPfEcnk0DBgzQ/PnzNXr0aF122WW6+eabz5gpV66cJGn//v2l3s/xZ84n3sZmFnxfO9G3335b7Pfo6Gi/Ij18+PBPjqVLly565513ik0HsmvXLk2fPl1t2rTxl1px8eJK4SzJyMjQ9OnTdccdd6hRo0bFvtG8ZMkSvfXWWxo0aFDwdp9//nn985//1PXXX6/BgwcrMzNT+/bt0/Lly/Xhhx9q3759ko69ZPHGG2/oN7/5jT7//HO1bdtWBw8e1IcffqihQ4eqR48eJbbds2dPf1kgOTlZEyZMOO04brnlFo0aNUpdu3bVnXfeqd27d2vcuHGqW7euVq5cGXxckvT0009r7ty5atu2rYYOHaqjR49qzJgxaty4cdA2e/furaFDh+qdd95Renq62rVrV+zv48aNU5s2bdS0aVMNHjxYderU0a5du7R06VJt27ZNK1asiGj8P+XOO+/UsGHDNHv2bD3wwANnvHqTjr2UkpmZqTfffFP169dX5cqV1aRJEzVp0uS0mYYNGyojI0OPPfaYtm/fruTkZM2aNetnvcZ+3333ad++ferYsaPS0tK0efNmjRkzRldddZUaNWr0k9k///nPWrBggdq0aaOhQ4eqTJkymjBhgg4fPqwXXngh4jHhPLpQH3v6pVq3bp0NHjzYatWqZXFxcVa+fHlr3bq1jRkzpthHIvV/X/A6Wc2aNS0nJ6fYsl27dtmDDz5o6enpFhsba6mpqdapUyebOHFisfXy8/PtiSeesNq1a/t6t912m3888HQfI3zllVdMkj322GM/eWyvvfaafzGuYcOGNnny5FN+0Szk2D766CO7+uqrLS4uLujLayfr06ePSbJhw4ad8u8bN260gQMHWmpqqsXGxlqNGjUsOzvb3n77bV/n+Mck//Wvf5XIl/YjqSfq1q2bSbIlS5aU+jiWLFni50On+PLaqaxZs8Y6d+5sSUlJVqVKFRs8eLB/BPjEj2qebhsnn++3337bunTp4l+WvOKKK2zIkCG2c+dOX+d09yWzY19ey8rKsqSkJCtXrpzdeOONJc7BT53r419eO1nNmjXtlltuKbH8dPc3RCbKjHdogHOhV69eWrVqlTZs2HChhwKUGu8pAOfAzp079f7772vAgAEXeihAEN5TAM6i3Nxcffrpp/rb3/6m2NhYDRky5EIPCQjClQJwFn300UcaMGCAcnNzNWXKFKWmpl7oIQFBeE8BAOC4UgAAOEoBAOBK/UbziTNelhYzFwLAmZ08p1VpvPjii8GZRx555MxjCd4qAOAXi1IAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgylzoAQCXmujoyJ6LpaWlBWeuvfba4Ey1atWCM8uWLQvOLF++PDgjSUVFRRHlUDpcKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAADHhHiISJky4XedxMTEiPZVvnz54ExqampwJiEhITgTydji4uKCM5LUrFmz4Ez//v2DM7Vq1QrOPPvss8GZlStXBmckqaCgIKIcSocrBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOCYEO8XJjY2NjhTo0aN4Mw111wTnKlTp05wRopscrt69eoFZ5KTk4MzVapUCc7ExMQEZ6TIJhRMS0uLaF+hypUrF5yJjuY56cWIWwUA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4JsQ7DyKZAK1mzZoR7atHjx7BmVatWgVnWrZsGZxJSkoKzkjS3r17gzNbt24NzmzevDk4ExUVFZxp06ZNcCbSfUXi8OHDwZlDhw4FZ4qKioIzOPe4UgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOCfECxcfHB2eaNm0anLn33nuDM5KUnZ0dnElMTAzOrF+/PjizdOnS4IwkrVixIjizZcuW4Ewkk7rdcccdwZlIJiCUpMLCwuBMJJMx7tq1KzgTyQSEkRwPzj2uFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAA7pKeJTU6OrwTMzIygjOPPvpocKZ79+7BGSmy2Spff/314MyyZcuCM1988UVwRops1k4zC85Ur149OLN9+/bgTKSzxVasWDE4U7du3eDM559/Hpz57LPPgjPMknpx4koBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAuEt6QrzY2NjgzJVXXhmc6dq1a3AmLy8vOCNJL7/8cnDmzTffDM7s378/OHOx27dvX3Dm3XffDc5s3rw5OCNJffv2Dc5EMoHjqlWrgjNr164NzuDixJUCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcEyIF6hWrVrBmbi4uODM7t27gzOS9MUXXwRnDh48GJyJjj5/zyfM7Lxkfvzxx+BMJBPBVahQITgjSdWqVQvO7Ny5MziTm5sbnCkqKgrO4OLElQIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABwl/SEeIWFhcGZb7/99rzsp3r16sEZSRo+fHhwJpJJ3b7++uvgzPfffx+ckaRdu3YFZ1auXBmc2bNnT3CmSpUqwZmbbropOCNJdevWDc7MmDEjOLNw4cLgDH45uFIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAALhLepbUgoKC4MzixYuDMzNnzgzOZGVlBWckqXXr1sGZDh06BGcimVH00KFDwRlJ2r9/f3Dmq6++Cs5EckyVKlUKzrRq1So4I0lFRUXBmR07dgRnIpnNNioqKjhjZsEZnHtcKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAAB3SU+IV1hYGJzJzc0NzowaNSo48+GHHwZnJCklJSU406BBg+BMRkZGcCYhISE4I0U22Vrz5s2DM7Vr1w7OlCtXLjgTGxsbnJGk/Pz84EzPnj2DM6mpqcGZhQsXBmcWLVoUnJGkvLy8iHIoHa4UAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgLukJ8SLxOHDh4Mz69atC86sX78+OCNJ8fHxwZnLLrssOBPJpGmRTgSXlJQUnLn99tuDMw0bNgzOHDlyJDizYsWK4Iwk7d27NzgTyWSHAwYMCM60bNkyOFNQUBCckSKbfC+Sf7eXKq4UAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgGNCvIuUmUWU+/HHH4Mz27dvD87s2LEjOFO1atXgjCR17do1ONOoUaPgTCTnbtmyZcGZN954IzgjSVu3bg3ONG/ePDhz1113BWdatGgRnMnMzAzOSNKnn34anGFCvNLjSgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4JsSDoqPDnxvUr18/ODN06NDgjCRlZ2cHZ8qUCb9rT5s2LTgzZcqU4MyXX34ZnJEim7AvPz8/ONOlS5fgzA8//BCc2bVrV3BGiuw8oPS4UgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOGZJvUjFxMRElKtatWpwpmXLlsGZzp07B2duuumm4IwkxcfHB2cmTZoUnJkxY0ZwZt26dcGZo0ePBmekyGZ+bdq0aXCmUaNGwZmVK1cGZ1avXh2ckaSCgoKIcigdrhQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAY0K8QNHR4T2akpISnOnVq1dwRpLat28fnKlfv35wpmLFisGZjRs3Bmck6aOPPgrORDK53aZNm4IzRUVFwZlIVapUKTjTrFmz4Ewk99fZs2cHZyI53zj3uFIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAA7pKeEK9MmfDDz8zMDM7069cvONO7d+/gjCRVrVo1OLNgwYLgzMKFC4Mza9euDc5I0rp164IzO3fuDM6YWXAmkgkSExISgjOS1K1bt+BMVlZWcGb9+vXBmcWLFwdnDhw4EJzBuceVAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHCX9IR4kUxM1rVr1+DMoEGDgjOXX355cEaKbCK48zUhXiSTx0lSYmJicKZu3boR7StUcnJycKZt27YR7SsnJyc4U6NGjeDMyy+/HJz5+OOPgzNFRUXBGZx7XCkAABylAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAAd0lPiHf06NHgzJYtW4IzeXl5wZnKlSsHZ6TIJmiLZMK+7Ozs4ExSUlJwRpKioqKCM2Z2XjKxsbHBmdTU1OBMpCZNmhScmTlzZnDmwIEDwRlcnLhSAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAC4S3qW1IKCguDMwoULgzP5+fnBmWuvvTY4I0n16tULzlx22WXBmfT09OBMo0aNgjOSFBMTE5z54YcfgjORzIC7Y8eO4Ewk9yFJWrRoUXBm6dKlwZmtW7cGZ/DLwZUCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJf0hHhFRUXBmd27dwdn5s6dG5z5/PPPgzOSVLly5eBM2bJlgzOJiYnBmUjGJklRUVHBmSNHjgRn9u/fH5yJZOK9AwcOBGckaefOncGZQ4cORbQvXLq4UgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAADukp4Q73wpKCgIznzzzTcR7SvSHABIXCkAAE5AKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAXJnSrhgVFRW88UgyAHCpuZgeK7lSAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAK7UE+I98cQTwRs/cOBAcAYALjWRTIjXrl27czASrhQAACegFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4KLMzC70IAAAFweuFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAO7/AX2iudDF1Ti+AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(image)\n",
        "    prediction = output.argmax(dim=1)\n",
        "\n",
        "print(\"Predicted digit:\", prediction.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pluq94ha_kJV",
        "outputId": "7ef82b50-6bad-4ebb-ab9c-d0785961ee8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted digit: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|Actual|Recognised|\n",
        "|:----:|:--------:|\n",
        "|  0   |    0     |\n",
        "|  1   |    3     |\n",
        "|  2   |    2     |\n",
        "|  3   |    3     |\n",
        "|  4   |    7     |\n",
        "|  5   |    5     |\n",
        "|  6   |    6     |\n",
        "|  7   |    3     |\n",
        "|  8   |    3     |\n",
        "|  9   |    3     |\n"
      ],
      "metadata": {
        "id": "wttETjcBGHhB"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}