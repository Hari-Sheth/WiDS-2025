{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        " **Intel Image Classification Dataset **\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "7FMZ7nbisz6Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jEl3GblrO97"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import kagglehub\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"puneet6060/intel-image-classification\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NYE0dqNpx4q",
        "outputId": "208cdfdc-cfac-4fca-9210-2b53de6f89b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'intel-image-classification' dataset.\n",
            "Path to dataset files: /kaggle/input/intel-image-classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MczSY33op4BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "65bVZcKyMkiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels = 3, num_classes = 7):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = (3,3), stride = (1,1), padding = (1,1))\n",
        "        self.pool = nn.MaxPool2d(kernel_size = (2,2), stride = (2,2))\n",
        "        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = (3,3), stride = (1,1), padding = (1,1))\n",
        "        self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (3,3), stride = (1,1), padding = (1,1))\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc1 = nn.Linear(64*8*8, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "jQOSxRLwr7py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "in_channels = 3\n",
        "num_classes = 6\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "u3EcC_mY0vJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
        "])\n"
      ],
      "metadata": {
        "id": "X40Cnx7X1FpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(\n",
        "    root=os.path.join(path,'seg_train','seg_train'),\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    root=os.path.join(path,'seg_test','seg_test'),\n",
        "    transform=transform\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZIZQBn-gM1MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "test_data = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = batch_size,\n",
        "    num_workers=4\n",
        ")\n",
        "\"\"\"\n",
        "print(\"Classes:\", train_dataset.classes)\n",
        "print(\"Number of training images:\", len(train_dataset))\n",
        "print(\"Number of validation images:\", len(test_dataset))\n",
        "\n",
        "# Optional: check a batch\n",
        "images, labels = next(iter(train_data))\n",
        "print(\"Batch image shape:\", images.shape)\n",
        "print(\"Batch label shape:\", labels.shape)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "pm--r3zm-4d6",
        "outputId": "a45fbeb3-0e51-4cc9-9496-78aab36b7c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(\"Classes:\", train_dataset.classes)\\nprint(\"Number of training images:\", len(train_dataset))\\nprint(\"Number of validation images:\", len(test_dataset))\\n\\n# Optional: check a batch\\nimages, labels = next(iter(train_data))\\nprint(\"Batch image shape:\", images.shape)\\nprint(\"Batch label shape:\", labels.shape)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "loss_criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A8fFg68NmRi",
        "outputId": "95fdd9d7-ffb3-4171-f69e-103c0a3add68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              "  (fc1): Linear(in_features=4096, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "i = 0\n",
        "for epoch in range(num_epochs):\n",
        "    i += 1\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_data:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        labels = labels.long()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = loss_criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss/len(train_data)\n",
        "    print(i, \" Epoch: \", (epoch+1)/(num_epochs), \" Loss: \", epoch_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxHF4L__OZ8a",
        "outputId": "259f25b7-76fe-49e9-c4de-8a158f0a2533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1  Epoch:  0.01  Loss:  1.1281343606385317\n",
            "2  Epoch:  0.02  Loss:  0.8691366228190336\n",
            "3  Epoch:  0.03  Loss:  0.7823724378239024\n",
            "4  Epoch:  0.04  Loss:  0.7050882529128681\n",
            "5  Epoch:  0.05  Loss:  0.6668708503246308\n",
            "6  Epoch:  0.06  Loss:  0.6248153513128107\n",
            "7  Epoch:  0.07  Loss:  0.5921637759967284\n",
            "8  Epoch:  0.08  Loss:  0.5600108954039487\n",
            "9  Epoch:  0.09  Loss:  0.5344286693768068\n",
            "10  Epoch:  0.1  Loss:  0.520687382329594\n",
            "11  Epoch:  0.11  Loss:  0.5051428989930586\n",
            "12  Epoch:  0.12  Loss:  0.4786868201060729\n",
            "13  Epoch:  0.13  Loss:  0.45537140206857163\n",
            "14  Epoch:  0.14  Loss:  0.45268621038306844\n",
            "15  Epoch:  0.15  Loss:  0.42970964312553406\n",
            "16  Epoch:  0.16  Loss:  0.41745166968215597\n",
            "17  Epoch:  0.17  Loss:  0.39994765398177234\n",
            "18  Epoch:  0.18  Loss:  0.38517884747548536\n",
            "19  Epoch:  0.19  Loss:  0.3704803767529401\n",
            "20  Epoch:  0.2  Loss:  0.3635573588988998\n",
            "21  Epoch:  0.21  Loss:  0.33926655026999386\n",
            "22  Epoch:  0.22  Loss:  0.3443336684595455\n",
            "23  Epoch:  0.23  Loss:  0.33098961372267116\n",
            "24  Epoch:  0.24  Loss:  0.30705328055403447\n",
            "25  Epoch:  0.25  Loss:  0.2999567010185935\n",
            "26  Epoch:  0.26  Loss:  0.2935750540007244\n",
            "27  Epoch:  0.27  Loss:  0.28342809758403087\n",
            "28  Epoch:  0.28  Loss:  0.272034774991599\n",
            "29  Epoch:  0.29  Loss:  0.26338526511734184\n",
            "30  Epoch:  0.3  Loss:  0.25282538424838674\n",
            "31  Epoch:  0.31  Loss:  0.24130133647810328\n",
            "32  Epoch:  0.32  Loss:  0.2438887174156579\n",
            "33  Epoch:  0.33  Loss:  0.23543233261867003\n",
            "34  Epoch:  0.34  Loss:  0.22025834687731483\n",
            "35  Epoch:  0.35  Loss:  0.21270633895288815\n",
            "36  Epoch:  0.36  Loss:  0.2010136452588168\n",
            "37  Epoch:  0.37  Loss:  0.1973603461276401\n",
            "38  Epoch:  0.38  Loss:  0.19527236812494017\n",
            "39  Epoch:  0.39  Loss:  0.18800718411803247\n",
            "40  Epoch:  0.4  Loss:  0.17268575985323298\n",
            "41  Epoch:  0.41  Loss:  0.16968851739710028\n",
            "42  Epoch:  0.42  Loss:  0.16170866800980135\n",
            "43  Epoch:  0.43  Loss:  0.17501713735136118\n",
            "44  Epoch:  0.44  Loss:  0.15647491507909514\n",
            "45  Epoch:  0.45  Loss:  0.15708434561436826\n",
            "46  Epoch:  0.46  Loss:  0.15631820630620827\n",
            "47  Epoch:  0.47  Loss:  0.14130992655726995\n",
            "48  Epoch:  0.48  Loss:  0.1446939143267545\n",
            "49  Epoch:  0.49  Loss:  0.1351827308535576\n",
            "50  Epoch:  0.5  Loss:  0.14105259227481756\n",
            "51  Epoch:  0.51  Loss:  0.13357336063953965\n",
            "52  Epoch:  0.52  Loss:  0.12416229549456727\n",
            "53  Epoch:  0.53  Loss:  0.11849651895463467\n",
            "54  Epoch:  0.54  Loss:  0.12135854630985043\n",
            "55  Epoch:  0.55  Loss:  0.11319234672595155\n",
            "56  Epoch:  0.56  Loss:  0.12362497387961909\n",
            "57  Epoch:  0.57  Loss:  0.11281200332397764\n",
            "58  Epoch:  0.58  Loss:  0.11925508119165898\n",
            "59  Epoch:  0.59  Loss:  0.11334972002289512\n",
            "60  Epoch:  0.6  Loss:  0.10058497955853289\n",
            "61  Epoch:  0.61  Loss:  0.09916133431887085\n",
            "62  Epoch:  0.62  Loss:  0.11192991394888271\n",
            "63  Epoch:  0.63  Loss:  0.09237934191795913\n",
            "64  Epoch:  0.64  Loss:  0.09493169642307542\n",
            "65  Epoch:  0.65  Loss:  0.09010534333911809\n",
            "66  Epoch:  0.66  Loss:  0.09315332821147009\n",
            "67  Epoch:  0.67  Loss:  0.09472079856151884\n",
            "68  Epoch:  0.68  Loss:  0.0896105206148191\n",
            "69  Epoch:  0.69  Loss:  0.0856045933609659\n",
            "70  Epoch:  0.7  Loss:  0.0910590970042077\n",
            "71  Epoch:  0.71  Loss:  0.09194845626638694\n",
            "72  Epoch:  0.72  Loss:  0.07544561907310378\n",
            "73  Epoch:  0.73  Loss:  0.07469885389913213\n",
            "74  Epoch:  0.74  Loss:  0.08453700826926665\n",
            "75  Epoch:  0.75  Loss:  0.0719590939920057\n",
            "76  Epoch:  0.76  Loss:  0.08441081228242679\n",
            "77  Epoch:  0.77  Loss:  0.08889288577166471\n",
            "78  Epoch:  0.78  Loss:  0.07661477410319177\n",
            "79  Epoch:  0.79  Loss:  0.08338556257499889\n",
            "80  Epoch:  0.8  Loss:  0.06667010499672456\n",
            "81  Epoch:  0.81  Loss:  0.07364151032472199\n",
            "82  Epoch:  0.82  Loss:  0.07344048553231088\n",
            "83  Epoch:  0.83  Loss:  0.07946380505507643\n",
            "84  Epoch:  0.84  Loss:  0.07244436455551874\n",
            "85  Epoch:  0.85  Loss:  0.07423882614821195\n",
            "86  Epoch:  0.86  Loss:  0.06480987105010586\n",
            "87  Epoch:  0.87  Loss:  0.0752343538640575\n",
            "88  Epoch:  0.88  Loss:  0.06710446981543844\n",
            "89  Epoch:  0.89  Loss:  0.0626193665984002\n",
            "90  Epoch:  0.9  Loss:  0.057094486201690005\n",
            "91  Epoch:  0.91  Loss:  0.05928694151172584\n",
            "92  Epoch:  0.92  Loss:  0.06514255964959209\n",
            "93  Epoch:  0.93  Loss:  0.07071161950853738\n",
            "94  Epoch:  0.94  Loss:  0.06358358751643788\n",
            "95  Epoch:  0.95  Loss:  0.06558739770711823\n",
            "96  Epoch:  0.96  Loss:  0.06141788602213968\n",
            "97  Epoch:  0.97  Loss:  0.05702371581203558\n",
            "98  Epoch:  0.98  Loss:  0.06320531107485294\n",
            "99  Epoch:  0.99  Loss:  0.05275155670348216\n",
            "100  Epoch:  1.0  Loss:  0.06698035383597016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.class_to_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE2AWkvrBajY",
        "outputId": "a13d6d55-a4ac-4634-c004-1eb16a3da47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'buildings': 0,\n",
              " 'forest': 1,\n",
              " 'glacier': 2,\n",
              " 'mountain': 3,\n",
              " 'sea': 4,\n",
              " 'street': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_data:\n",
        "  images, labels = images.to(device), labels.to(device)\n",
        "  images = images.float()\n",
        "  labels = labels.long()\n",
        "  output = model(images)\n",
        "  loss = loss_criterion(output, labels)\n",
        "  correct += (output.argmax(1) == labels).sum().item()\n",
        "  total += labels.size(0)\n",
        "print(100*correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQCB1bzZrpP7",
        "outputId": "90b2ed10-ee66-448c-bcc5-6c2146dbe2aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81.33333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_image = Image.open(\"/content/drive/MyDrive/Colab Notebooks/WiDS Assignments/2/seg_pred/seg_pred/76.jpg\")\n",
        "image = Image.open(\"/content/drive/MyDrive/forest.png\")\n",
        "\n",
        "transformer = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.Lambda(lambda image: image.convert(\"RGB\")),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
        "])\n",
        "image = transformer(image)\n",
        "image.to(device)\n",
        "print(image.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICDwNeNPu0kE",
        "outputId": "805c9715-8a3c-4222-ad04-3a683a0b12ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "image = image.unsqueeze(0)\n",
        "image = image.to(device)\n",
        "with torch.no_grad():\n",
        "    output = model(image)\n",
        "    prediction = output.argmax(dim=1)\n",
        "\n",
        "my_dict = train_dataset.class_to_idx\n",
        "target_value = prediction.item()\n",
        "\n",
        "found_key = next((key for key, val in my_dict.items() if val == target_value), None)\n",
        "\n",
        "print(\"Predicted class:\", found_key)\n",
        "\n",
        "probs = F.softmax(output, dim=1)\n",
        "\n",
        "print(probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yjy7IR6v03T",
        "outputId": "c3a15402-11db-4214-986f-61497280523c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: forest\n",
            "tensor([[3.1973e-14, 1.0000e+00, 4.0406e-09, 1.1863e-15, 1.6100e-18, 1.0752e-18,\n",
            "         1.8981e-24]], device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}